spring.application.name=data-modeling-service

# Docker Compose DB Configuration (use the service name as the host)
spring.datasource.url=jdbc:postgresql://postgres-db:5432/datamodelingdb
# Use your specific user credentials defined in your docker-compose.yml
spring.datasource.username=youruser 
spring.datasource.password=yourpassword 

# Kafka Configuration (Assuming Kafka is also run via Docker Compose)
spring.kafka.consumer.bootstrap-servers=kafka:29092
spring.kafka.consumer.group-id=data-modeling-consumer-group
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=false 
# Also include the producer property for completeness
spring.kafka.producer.bootstrap-servers=kafka:29092

# Spring Batch Configuration
# Set to 'never' as we manually manage schema creation in Postgres
spring.batch.initialize-schema=never 
spring.batch.job.enabled=false 
spring.batch.jdbc.initialize-schema=never
spring.batch.jdbc.abstract-batch-jdbc-dao.set-database-type=POSTGRES

# Actuator Configuration
management.endpoints.web.exposure.include=health,info,metrics,prometheus
